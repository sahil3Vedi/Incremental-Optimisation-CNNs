{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMnaR64bBX6QYAtb/3Suvqr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahil3Vedi/Incremental-Optimisation-CNNs/blob/main/LeNet5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhdgMMSvmgUr"
      },
      "source": [
        "'''\n",
        "Implementing LeNet 5 on the MNIST dataset using Keras\n",
        "'''\n",
        "# Credits to https://github.com/vaibhavcodes/DeepLearning-Architectures for providing the starter code\n",
        "\n",
        "# Importing Libraries\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, AvgPool2D, Flatten, Dense\n",
        "#from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "# Image processing & plotting\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_DxUKaBr4Ye",
        "outputId": "2ea31dae-b09d-4007-908a-55ff4eb89a64"
      },
      "source": [
        "# Loading the dataset and performing train-test split\n",
        "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
        "\n",
        "# Checking the sizes of train and test split\n",
        "print(\"The size of train_x is: {}\".format(train_x.shape))\n",
        "print(\"The size of train_y is: {}\".format(train_y.shape))\n",
        "print(\"The size of test_x is: {}\".format(test_x.shape))\n",
        "print(\"The size of test_y is: {}\".format(test_y.shape))\n",
        "\n",
        "# Performing reshaping operations = Converting into 4D\n",
        "train_x = train_x.reshape(train_x.shape[0], 28, 28, 1)\n",
        "test_x = test_x.reshape(test_x.shape[0], 28, 28, 1)\n",
        "\n",
        "# Normalizing the values of the image- Converting in between 0 and 1\n",
        "train_x = train_x/255.0\n",
        "test_x = test_x/255.0\n",
        "\n",
        "# One-hot encoding the labels\n",
        "train_y = to_categorical(train_y, num_classes=10)\n",
        "test_y = to_categorical(test_y, num_classes=10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "The size of train_x is: (60000, 28, 28)\n",
            "The size of train_y is: (60000,)\n",
            "The size of test_x is: (10000, 28, 28)\n",
            "The size of test_y is: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An4jUmDbstpj",
        "outputId": "05932e58-4daa-489d-d2c8-eeff5e3d9627"
      },
      "source": [
        "# Building the Model Architecture\n",
        "\n",
        "# Instanciate an empty model\n",
        "model = Sequential()\n",
        "\n",
        "# Adding a Convolution Layer C1\n",
        "# Input shape = N = (28 x 28)\n",
        "# No. of filters  = 6\n",
        "# Filter size = f = (5 x 5)\n",
        "# Padding = P = 0\n",
        "# Strides = S = 1\n",
        "# Size of each feature map in C1 is (N-f+2P)/S +1 = 28-5+1 = 24\n",
        "# No. of parameters between input layer and C1 = (5*5 + 1)*6 = 156\n",
        "model.add(Conv2D(filters=6, kernel_size=(5,5), padding='valid', input_shape=(28,28,1), activation='tanh'))\n",
        "\n",
        "# Adding an Average Pooling Layer S2\n",
        "# Input shape = N = (24 x 24)\n",
        "# No. of filters = 6\n",
        "# Filter size = f = (2 x 2)\n",
        "# Padding = P = 0\n",
        "# Strides = S = 2\n",
        "# Size of each feature map in S2 is (N-f+2P)/S +1 = (24-2+0)/2+1 = 11+1 = 12\n",
        "# No. of parameters between C1 and S2 = (1+1)*6 = 12\n",
        "model.add(AvgPool2D(pool_size=(2,2)))\n",
        "\n",
        "# Adding a Convolution Layer C3\n",
        "# Input shape = N = (12 x 12)\n",
        "# No. of filters  = 16\n",
        "# Filter size = f = (5 x 5)\n",
        "# Padding = P = 0\n",
        "# Strides = S = 1\n",
        "# Size of each feature map in C3 is (N-f+2P)/S +1 = 12-5+1 = 8\n",
        "# No. of parameters between S2 and C3 = (5*5*6*16 + 16) + 16 = 2416\n",
        "model.add(Conv2D(filters=16, kernel_size=(5,5), padding='valid', activation='tanh'))\n",
        "\n",
        "# Adding an Average Pooling Layer S4\n",
        "# Input shape = N = (8 x 8)\n",
        "# No. of filters = 16\n",
        "# Filter size = f = (2 x 2)\n",
        "# Padding = P = 0\n",
        "# Strides = S = 2\n",
        "# Size of each feature map in S4 is (N-f+2P)/S +1 = (8-2+0)/2+1 = 3+1 = 4\n",
        "# No. of parameters between C3 and S4 = (1+1)*16 = 32\n",
        "model.add(AvgPool2D(pool_size=(2,2)))\n",
        "\n",
        "# As compared to LeNet-5 architecture there was one more application of convolution but in our code  further application of \n",
        "# convolution with (5 x 5) filter would result in a negative dimension which is not possible. So we aren't applying any more\n",
        "# convolution here.\n",
        "\n",
        "# Flattening the layer S4\n",
        "# There would be 16*(4*4) = 256 neurons\n",
        "model.add(Flatten())\n",
        "\n",
        "# Adding a Dense layer with `tanh` activation+# \n",
        "# No. of inputs = 256\n",
        "# No. of outputs = 120\n",
        "# No. of parameters = 256*120 + 120 = 30,840\n",
        "model.add(Dense(120, activation='tanh'))\n",
        "\n",
        "# Adding a Dense layer with `tanh` activation\n",
        "# No. of inputs = 120\n",
        "# No. of outputs = 84\n",
        "# No. of parameters = 120*84 + 84 = 10,164\n",
        "model.add(Dense(84, activation='tanh'))\n",
        "\n",
        "# Adding a Dense layer with `softmax` activation\n",
        "# No. of inputs = 84\n",
        "# No. of outputs = 10\n",
        "# No. of parameters = 84*10 + 10 = 850\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 24, 24, 6)         156       \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 12, 12, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 8, 8, 16)          2416      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 120)               30840     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 44,426\n",
            "Trainable params: 44,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKUxFDc-svwD",
        "outputId": "db362369-c3b8-4216-976e-4e0109186329"
      },
      "source": [
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_x, train_y, batch_size=128, epochs=20, verbose=1, validation_data=(test_x, test_y))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 32s 7ms/step - loss: 0.3452 - accuracy: 0.9020 - val_loss: 0.1561 - val_accuracy: 0.9532\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.1274 - accuracy: 0.9611 - val_loss: 0.0995 - val_accuracy: 0.9683\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0820 - accuracy: 0.9747 - val_loss: 0.0697 - val_accuracy: 0.9767\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0618 - accuracy: 0.9808 - val_loss: 0.0653 - val_accuracy: 0.9798\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0500 - accuracy: 0.9851 - val_loss: 0.0554 - val_accuracy: 0.9815\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0421 - accuracy: 0.9871 - val_loss: 0.0519 - val_accuracy: 0.9821\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0354 - accuracy: 0.9892 - val_loss: 0.0453 - val_accuracy: 0.9847\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0306 - accuracy: 0.9903 - val_loss: 0.0438 - val_accuracy: 0.9849\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 0.0466 - val_accuracy: 0.9854\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 0.0474 - val_accuracy: 0.9846\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.0532 - val_accuracy: 0.9835\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0164 - accuracy: 0.9950 - val_loss: 0.0428 - val_accuracy: 0.9862\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0146 - accuracy: 0.9955 - val_loss: 0.0452 - val_accuracy: 0.9868\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 0.0465 - val_accuracy: 0.9860\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.0517 - val_accuracy: 0.9851\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.0427 - val_accuracy: 0.9875\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.0502 - val_accuracy: 0.9867\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0496 - val_accuracy: 0.9858\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0524 - val_accuracy: 0.9851\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.0477 - val_accuracy: 0.9863\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb05012ecd0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI8SD06Zsy7b",
        "outputId": "52c7f4d2-5957-4f2f-9068-f9be8c552ce5"
      },
      "source": [
        "# Finding the loss and accuracy of the model\n",
        "score = model.evaluate(test_x, test_y)\n",
        "\n",
        "print('Test Loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0477 - accuracy: 0.9863\n",
            "Test Loss: 0.04769694805145264\n",
            "Test accuracy: 0.986299991607666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "RZN1YsStBPA1",
        "outputId": "af72554d-c4df-4855-9bd5-738022961e31"
      },
      "source": [
        "sample_input  = train_x[1].reshape(28,28)\n",
        "fig = plt.figure\n",
        "plt.imshow(sample_input, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r_IFcK2BmWv"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}